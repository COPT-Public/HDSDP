\section{Introduction}

Semidefinite programming (SDP) is a mathematical programming problem defined
by
\begin{eqnarray}
  \min_{\mathbf{X}} & \left\langle \mathbf{C}, \mathbf{X} \right\rangle & \nonumber \\
  \text{subject to} & \mathcal{A} \mathbf{X} = \mathbf{b} & \\ 
  & \mathbf{X} \in \mathbb{S}_+^n, & \nonumber
\end{eqnarray}
where we study linear optimization subject to affine constraints over the cone of
positive-semidefinite matrices. Due to its extensive modeling capability, SDP
has been employed in various communities including combinatorial
optimization{\cite{goemans1995improved, laurent2005semidefinite}},
dynamic systems {\cite{vandenberghe1996semidefinite}}, sums of squares
optimization{\cite{laurent2009sums}}, quantum
information{\cite{hayashi2016quantum}}, and distance geometry
{\cite{biswas2004semidefinite, so2007theory}}. We refer the interested
readers to {\cite{wolkowicz2005semidefinite}} for a more comprehensive review
of SDP applications. \\

While SDP proves useful in many applications, a fundamental issue is how to
numerically solve them. Theoretically, SDP is a convex conic problem which
admits efficient polynomial-time algorithms and for general SDPs, the interior
point method (IPM) is known as a most robust and efficient approach. Since the
1990s, high-performance SDPs softwares based on the IPM have been developed,
including {{\texttt{DSDP}}} {\cite{benson2008algorithm}}, \text{{\ttfamily{COPT}}}
{\cite{copt}}, \text{{\ttfamily{Mosek}}} {\cite{aps2019mosek}}, \text{{\ttfamily{Sedumi}}}
{\cite{polik2007sedumi}}, \text{{\ttfamily{SDPT3}}} {\cite{toh2012implementation}},
\text{{\ttfamily{CSDP}}} {\cite{borchers2006csdp}} and \text{{\ttfamily{SDPA}}}
{\cite{yamashita2012latest}}. While most SDP codes implement the IPM, there also exist
a number of successful attempts adopting other algorithms including
{\cite{kocvara2006pensdp, kwasniewiczimplementation, yang2015sdpnal}}
and a list of such SDP software is available from {\cite{majumdar2020recent}}.\\

SDP solvers based on different IPM variants enjoy nice convergence behavior
both theoretically and practically. Most SDP solvers implement a
path-following primal-dual approach either using infeasible start
{\cite{potra1998superlinearly}} or the homogeneous self-dual embedding
{\cite{potra1998homogeneous}} with {{\texttt{DSDP}}} being an exception.
{{\texttt{DSDP}}} implements a dual IPM method based on the potential reduction framework 
proposed in {\cite{benson1999mixed}}.
Since the initial release {\cite{benson2000solving}}, {{\texttt{DSDP}}} has
gone a long way through several major updates and evolved into an
efficient and robust solver for general SDPs {\cite{benson2008algorithm}}.
To further enhance the efficiency and robustness of {{\texttt{DSDP}}}, we make
another extension by incorporating the well-known homogeneous self-dual (HSD)
embedding into the dual algorithm. This new implementation, named
{{\texttt{HDSDP}}}, is presented in this manuscript.\\

The rest of the manuscript is organized as follows. \textbf{Section \ref{sec2}} 
describes the SDP formulation of interest and basic notations.
{\textbf{Section \ref{sec3}} reviews the dual-scaling algorithm for SDP
and describes how to combine it with the simplified HSD embedding. In {\textbf{Section
\ref{sec4}} and \textbf{\ref{sec5}}, we introduce the practical aspects for {{\texttt{HDSDP}}}. 
Last we present the computational results of various SDP problems.

\section{Formulation and Notations} \label{sec2}

{{\texttt{HDSDP}}} is interested in the standard form primal SDP and its dual

{\center{$\begin{array}{lccl}
  (P) & \min_{\mathbf{X}}  & \left\langle \mathbf{C}, \mathbf{X} \right\rangle & \\
  & \text{subject to} & \left\langle \mathbf{A}_i, \mathbf{X} \right\rangle = \mathbf{b}, & i = 1,
  \ldots, m\\
  &  & \mathbf{X} \in \mathbb{S}_+^n & 
\end{array}$\qquad$\begin{array}{lcc}
  (D) & \max_{\mathbf{y}, \mathbf{S}} & \mathbf{b}^{\top} \mathbf{y}\\
  & \text{subject to} & \sum_{i = 1}^m \mathbf{A}_i y_i + \mathbf{S} = \mathbf{C}\\
  &  & \mathbf{S} \in \mathbb{S}_+^n,
\end{array}$}}\\

where the problem data $\{\mathbf{A}_i\}, \mathbf{C}$ are $n \times n$ symmetric matrices
($\mathbb{S}^n$) and $\mathbf{b} \in \mathbb{R}^m$ is a real vector. Matrix inner
product $\langle \cdot, \cdot \rangle$ is defined by $\left\langle \mathbf{A}, \mathbf{X} \right\rangle := \sum_{k, l}
c_{i j} x_{i j}$ and $\mathbb{S}_+^n$ denotes the cone of positive
semidefinite matrices. For brevity we use $\mathbf{X} \succeq \textbf{0}$ to denote the
relation $\mathbf{X} \in \mathbb{S}_+^n$ and the linear map $\mathcal{A} : \mathbb{S}^n
\rightarrow \mathbb{R}^m$ and its adjoint $\mathcal{A}^{\ast} : \mathbb{R}^m
\rightarrow \mathbb{S}^n$ are respectively defined by $\mathcal{A} \mathbf{X} := \left(
\left\langle \mathbf{A}, \mathbf{X}_1 \right\rangle, \ldots, \left\langle \mathbf{A}_m, \mathbf{X}_m
\right\rangle \right)^{\top}$ and $\mathcal{A}^{\ast} \mathbf{y} := \sum_{i = 1}^m \mathbf{A}_i
y_i$. $\left\| \mathbf{A} \right\|_F := \sqrt{\sum_{i j} a_{i j}^2}$ denotes
matrix Frobenius norm. With the above notations, we rewrite the primal and
dual problems by

{\center{$\begin{array}{lccl}
  (P) & \min_{\mathbf{X}}  & \left\langle \mathbf{C}, \mathbf{X} \right\rangle & \\
  & \text{subject to} & \mathcal{A} \mathbf{X} = \mathbf{b}, & i = 1, \ldots, m\\
  &  & \mathbf{X} \succeq \textbf{0} & 
\end{array}$\qquad$\begin{array}{lcc}
  (D) & \max_{\mathbf{y}, \mathbf{S}} & \mathbf{b}^{\top} \mathbf{y}\\
  & \text{subject to} & \mathcal{A}^{\ast} \mathbf{y} + \mathbf{S} = \mathbf{C}\\
  &  & \mathbf{S} \succeq \textbf{0} .
\end{array}$}}\\

and the feasible regions for $(P)$ and $(D)$ are respectively
$\mathcal{F} (P) := \left\{ \mathbf{X} : \mathcal{A} \mathbf{X} = \mathbf{b}, \mathbf{X} \succeq \textbf{0} \right\}$
and $\mathcal{F} (D) := \left\{ \left( \mathbf{y}, \mathbf{S} \right) : \mathcal{A}^{\ast} \mathbf{y} +
\mathbf{S} = \mathbf{C}, \mathbf{S} \succeq \textbf{0} \right\}$. Any $\mathbf{X} \in \mathcal{F} (P)$ is called primal
feasible and $\left( \mathbf{y}, \mathbf{S} \right) \in \mathcal{F} (D)$ is dual feasible.
The interior of the feasible regions are denoted by $\mathcal{F}^0 (P),
\mathcal{F}^0 (D)$ and any point in $\mathcal{F}^0$ is called an interior
point solution. 

\begin{remark}
  Although in this manuscript we focus on the SDP of single-block for ease of
  exposition, a natural generalization to multi-block SDPs applies rather
  straightforward.
\end{remark}

{{\texttt{HDSDP}}} implements a dual method that solves both
({{\em P\/}}) and ({{\em D\/}}) through the simplified HSD and in the next
section we get down to the underlying theoretical details.

