@article{davis2018subgradient,
  title={Subgradient methods for sharp weakly convex functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy and MacPhee, Kellie J and Paquette, Courtney},
  journal={Journal of Optimization Theory and Applications},
  volume={179},
  number={3},
  pages={962--982},
  year={2018},
  publisher={Springer}
}

@article{charisopoulos2021low,
  title={Low-rank matrix recovery with composite optimization: good conditioning and rapid convergence},
  author={Charisopoulos, Vasileios and Chen, Yudong and Davis, Damek and D{\'\i}az, Mateo and Ding, Lijun and Drusvyatskiy, Dmitriy},
  journal={Foundations of Computational Mathematics},
  pages={1--89},
  year={2021},
  publisher={Springer}
}

@article{davis2019stochastic,
  title={Stochastic algorithms with geometric step decay converge linearly on sharp functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy and Charisopoulos, Vasileios},
  journal={arXiv preprint arXiv:1907.09547},
  year={2019}
}

@article{asi2019stochastic,
  title={Stochastic (approximate) proximal point methods: Convergence, optimality, and adaptivity},
  author={Asi, Hilal and Duchi, John C},
  journal={SIAM Journal on Optimization},
  volume={29},
  number={3},
  pages={2257--2290},
  year={2019},
  publisher={SIAM}
}

@article{asi2020minibatch,
  title={Minibatch Stochastic Approximate Proximal Point Methods},
  author={Asi, Hilal and Chadha, Karan and Cheng, Gary and Duchi, John C},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{deng2021minibatch,
  title={Minibatch and Momentum Model-based Methods for Stochastic Non-smooth Non-convex Optimization},
  author={Deng, Qi and Gao, Wenzhi},
  journal={arXiv preprint arXiv:2106.03034},
  year={2021}
}

@book{bertsekas2015convex,
  title={Convex optimization algorithms},
  author={Bertsekas, Dimitri},
  year={2015},
  publisher={Athena Scientific}
}